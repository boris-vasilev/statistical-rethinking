# 9.2 Metropolis algorithms

The island-hopping algorithm is a special case of the general **Metropolis algorithm**. This algorithm is an example of MCMC.

**The goal usually is to draw samples from an unknown, usually complex, target distribution, like a posterior probability distribution.**

-   The "*islands*" are the parameter values which don't have to be discrete, can be continuous as usual

-   The "*population sizes*" are the posterior probabilities of each parameter value

-   The "*weeks*" are samples taken from the joint posterior of the parameters in the model

Provided the way we choose the proposed parameter values at each step is symmetric - there's an equal chance of proposing A-\>B as B-\>A, then the Metropolis algorithm will eventually give us a collection of samples from the joint posterior. We can use these samples just like all the samples we've used so far.

## 9.2.1 Gibbs sampling

A more general method - the **Metropolis-Hastings algorithm** - works also with asymmetric proposal distributions. (In the King Markov example - this means that the coin that decides whether to go left or right can be biased)

Why asymmetric proposals?

-   Easier to handle parameters like standard deviation that have boundaries at zero

-   MOST IMPORTANTLY! Allows to generate savvy proposals that make it more efficient to explore the posterior - i.e. get a good image of the posterior with fewer steps

The most common way to generate savvy proposals is with **Gibbs sampling**, which is a variant of the Metropolis-Hastings algorithm.

The improvement (fewer steps) comes from *adaptive proposals* in which the distribution of proposed parameter values adjusts itself, depending on the current parameter values.

Gibbs sampling computes these adaptive proposals using particular combinations of prior distributions and likelihoods known as *conjugate pairs*.

Conjugate pairs have analytical solutions for the posterior distribution of an individual parameter.

## 9.2.2 High-dimensional problems

Conjugate priors are restrictive, sometimes we want a different prior.

As models become more complex with more parameters (a high-dimensional posterior), Gibbs sampling and Metropolis become extremely inefficient. They tend to get stuck in small regions of the posterior for a long time.

When there are more parameters it becomes increasingly more likely to have parameters that are correlated. This high correlation creates a narrow ridge in the posterior with high probability combinations and both Metropolis and Gibbs make dumb proposals of where to go next. So they get stuck.

**Figure 9.3**. With small step size, Metropolis moves slowly, with a relatively low acceptance rate because of the dumb proposals. And it moves slow because even when a proposal is accepted, it is only a little different from the previous. With a big step size, it moves faster, with a much lower acceptance rate. This is a tradeoff that is hard to win.

Gibbs and Metropolis get stuck because they don't know enough about the global shape of the posterior.

The problem is more general. Any Markov chain approach that samples individual parameters in individual steps is going to get stuck, once the number of parameters grows large.

The reason is known as **concentration of measure**. What it means is that most of the probability mass of a high-dimensional distribution is always very far from the mode of the distribution.

If we imagine a 2D Gaussian distribution - a hill - the highest probability is at it's mode. However if we get the surrounding ring around that hill. The combination of the two sides of the mode will have higher probability than the mode. The total probability increases as we move away from the mode. And eventually declines again as the hill slopes down to zero. So at some radial distance from the peak, probability mass is maximised (not at the peak/mode)

What this means is that if we sample a high dimensional posterior, most of the samples will come from this region of high probability and not the mode, the peak that maximises the probability.

To demonstrate we can sample a high-dimensional distribution and plot the radial distances of the points.

Each sample is 1000 points.

10 dimensions (D=10)

```{r}
library(rethinking)
D <- 10
T <- 1e3
Y <- rmvnorm(T,rep(0,D),diag(D))
rad_dist <- function( Y ) sqrt( sum(Y^2) )
Rd <- sapply( 1:T , function(i) rad_dist( Y[i,] ) )
dens( Rd , xlab="Radial distance from mode", ylab="Density")
mtext("10 dimensions (D=10)")
```

100 dimensions (D=100)

```{r}
D <- 100
T <- 1e3
Y <- rmvnorm(T,rep(0,D),diag(D))
rad_dist <- function( Y ) sqrt( sum(Y^2) )
Rd <- sapply( 1:T , function(i) rad_dist( Y[i,] ) )
dens( Rd , xlab="Radial distance from mode", ylab="Density")
mtext("100 dimensions (D=100)")
```

```{r}
D <- 1000
T <- 1e3
Y <- rmvnorm(T,rep(0,D),diag(D))
rad_dist <- function( Y ) sqrt( sum(Y^2) )
Rd <- sapply( 1:T , function(i) rad_dist( Y[i,] ) )
dens( Rd , xlab="Radial distance from mode", ylab="Density")
mtext("1000 dimensions (D=1000)")

```

It gets further and further from the mode as shown by the radial distance.

This shell can create very hard paths for a sampler to follow.

This is why we need MCMC algorithms that focus on the entire posterior at once, instead of one or a few dimensions at a time like Metropolis and Gibbs. Otherwise we get stuck in a narrow, highly curving region of parameter space.
